{
  "run_id": "390361b0ce93",
  "model": "llama3.1:8b",
  "silo": "__adversarial_eval__",
  "totals": {
    "total_queries": 5,
    "passed_queries": 5,
    "failed_queries": 0,
    "overall_trust_score": 100.0,
    "hallucination_rate": 0.0,
    "confident_error_rate": 0.0,
    "temporal_error_rate": 0.0,
    "unsupported_assertion_rate": 0.0,
    "forbidden_value_hit_count": 0,
    "decisive_direct_pass_count": 5,
    "expected_decisive_from_canonical_count": 0,
    "missing_allowed_source_count": 0
  },
  "category_breakdown": {
    "direct": {
      "total": 5,
      "passed": 5,
      "failed": 0
    }
  },
  "run_config": {
    "strict_mode": true,
    "direct_decisive_mode": null,
    "config_path": null
  },
  "failures": [],
  "records": [
    {
      "query_id": "Q001",
      "category": "direct",
      "passed": true,
      "subscores": {
        "factual_correctness": 1,
        "trust_behavior": 1,
        "evidence_grounding": 1,
        "temporal_correctness": null
      },
      "failure_reason": null,
      "answer_text": "Aster Grill revenue rank: 1\n\n---\nAnswered by: Adversarial Eval",
      "sources_seen": [
        "2025-03-01-canonical-rankings.md"
      ]
    },
    {
      "query_id": "Q002",
      "category": "direct",
      "passed": true,
      "subscores": {
        "factual_correctness": 1,
        "trust_behavior": 1,
        "evidence_grounding": 1,
        "temporal_correctness": null
      },
      "failure_reason": null,
      "answer_text": "Blue Harbor revenue rank: 2\n\n---\nAnswered by: Adversarial Eval",
      "sources_seen": [
        "2025-03-01-canonical-rankings.md"
      ]
    },
    {
      "query_id": "Q003",
      "category": "direct",
      "passed": true,
      "subscores": {
        "factual_correctness": 1,
        "trust_behavior": 1,
        "evidence_grounding": 1,
        "temporal_correctness": null
      },
      "failure_reason": null,
      "answer_text": "Ember Table revenue rank: 3\n\n---\nAnswered by: Adversarial Eval",
      "sources_seen": [
        "2025-03-01-canonical-rankings.md"
      ]
    },
    {
      "query_id": "Q004",
      "category": "direct",
      "passed": true,
      "subscores": {
        "factual_correctness": 1,
        "trust_behavior": 1,
        "evidence_grounding": 1,
        "temporal_correctness": null
      },
      "failure_reason": null,
      "answer_text": "Aster Grill delivery SLA minutes: 27\n\n---\nAnswered by: Adversarial Eval",
      "sources_seen": [
        "2025-02-15-canonical-ops-sla.md"
      ]
    },
    {
      "query_id": "Q005",
      "category": "direct",
      "passed": true,
      "subscores": {
        "factual_correctness": 1,
        "trust_behavior": 1,
        "evidence_grounding": 1,
        "temporal_correctness": null
      },
      "failure_reason": null,
      "answer_text": "Blue Harbor delivery SLA minutes: 30\n\n---\nAnswered by: Adversarial Eval",
      "sources_seen": [
        "2025-02-15-canonical-ops-sla.md"
      ]
    }
  ]
}